% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/lexical_density.R
\name{lex_density}
\alias{lex_density}
\title{Calculate lexical density}
\usage{
lex_density(vec, contents_words, targets = NULL, negate = c(FALSE, FALSE))
}
\arguments{
\item{vec}{A character vector.}

\item{contents_words}{A character vector containing values
to be counted as contents words.}

\item{targets}{A character vector with which
the denominator of lexical density is filtered before computing values.}

\item{negate}{A logical vector of which length is 2.
If supplied \code{TRUE}, then respectively negates the predicate functions
for counting contents words or targets.}
}
\value{
numeric vector.
}
\description{
Calculate lexical density
}
\examples{
\dontrun{
df <- tokenize(
  data.frame(
    doc_id = seq_len(length(audubon::polano[5:8])),
    text = audubon::polano[5:8]
  )
)
df |>
  prettify(col_select = "POS1") |>
  dplyr::group_by(doc_id) |>
  dplyr::summarise(
    noun_ratio = lex_density(POS1, "名詞", c("助詞", "助動詞"), negate = c(FALSE, TRUE)),
    mvr = lex_density(POS1, c("形容詞", "副詞", "連体詞"), "動詞"),
    vnr = lex_density(POS1, "動詞", "名詞")
  )
}
}
