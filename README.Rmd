---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
require(gibasa)
```

# gibasa

<!-- badges: start -->
[![gibasa status badge](https://paithiov909.r-universe.dev/badges/gibasa)](https://paithiov909.r-universe.dev)
![GitHub](https://img.shields.io/github/license/paithiov909/gibasa)
[![R-CMD-check](https://github.com/paithiov909/gibasa/workflows/R-CMD-check/badge.svg)](https://github.com/paithiov909/gibasa/actions)
[![codecov](https://codecov.io/gh/paithiov909/gibasa/branch/main/graph/badge.svg)](https://codecov.io/gh/paithiov909/gibasa)
<!-- badges: end -->

## Overview

Gibasa is a plain 'Rcpp' interface to 'MeCab', CJK tokenizer and morphological analysis tool for R.

The main goal of gibasa package is to provide an alternative to `tidytext::unnest_tokens` for CJK text data.
For analyzing CJK text data, it usually requires part-of-speech tagging,
as most of them are not separated with spaces and `tokenizers::tokenize_words` sometimes splits them into erroneous tokens.

Gibasa provides 3 main functions: `gibasa::tokenize`, `gibasa::prettify`, and `gibasa::pack`.

![image](man/figures/tidytext_fig5_1_mod.drawio.png)

- `gibasa::tokenize` retrieves a TIF-compliant data.frame of corpus, returning tokens as format that known as 'tidy text data', so that users can replace `tidytext::unnest_tokens` with it for tokenizing CJK text.
- `gibasa::prettify` turns tagged features into columns.
- `gibasa::pack` retrieves a 'tidy text data', typically returning space-separated corpus.

## Installation

You can install binary package via [r-universe](https://paithiov909.r-universe.dev/ui#package:gibasa).

```r
# Enable repository from paithiov909
options(repos = c(
  paithiov909 = "https://paithiov909.r-universe.dev",
  CRAN = "https://cloud.r-project.org"))

# Download and install gibasa in R
install.packages("gibasa")

# Or build from source package
Sys.setenv(MECAB_DEFAULT_RC = "/fullpath/to/your/mecabrc") # if necessary
remotes::install_github("paithiov909/gibasa")
```

To use gibasa package requires the [MeCab](https://taku910.github.io/mecab/) library and its dictionary installed and available.

In case using Linux or OSX, you can install them with their package managers, or build and install from the source by yourself.

In case using Windows, use installer [built for 32bit](https://drive.google.com/uc?export=download&id=0B4y35FiV1wh7WElGUGt6ejlpVXc) or [built for 64bit](https://github.com/ikegami-yukino/mecab/releases/tag/v0.996.2).
Note that gibasa requires a UTF-8 dictionary, not a Shift-JIS one.

## Usage

### Tokenize sentences

```{r}
res <- gibasa::tokenize(
  data.frame(
    doc_id = seq_along(audubon::polano[5:8]),
    text = audubon::polano[5:8]
  )
)
head(res)
```

### Prettify output

```{r}
head(gibasa::prettify(res))
head(gibasa::prettify(res, col_select = 1:3))
head(gibasa::prettify(res, col_select = c(1, 3, 5)))
head(gibasa::prettify(res, col_select = c("POS1", "Original")))
```

### Pack output

```{r}
res <- gibasa::prettify(res)
gibasa::pack(res)

dplyr::mutate(
  res,
  token = dplyr::if_else(is.na(Original), token, Original),
  token = paste(token, POS1, sep = "/")
) |>
  gibasa::pack() |>
  head(1L)
```

### Change dictionary

IPA, [UniDic](https://clrd.ninjal.ac.jp/unidic/), [CC-CEDICT-MeCab](https://github.com/ueda-keisuke/CC-CEDICT-MeCab), and [mecab-ko-dic](https://bitbucket.org/eunjeon/mecab-ko-dic/src/master/) schemes are supported.

```r
## UniDic 2.1.2
gibasa::gbs_tokenize("あのイーハトーヴォのすきとおった風", sys_dic = "/Downloads/unidic-lite") |> 
    gibasa::prettify(into = gibasa::get_dict_features("unidic26")) |> 
    head()
#>   doc_id sentence_id token_id          token   POS1     POS2 POS3 POS4
#> 1      1           1        1           あの 感動詞 フィラー <NA> <NA>
#> 2      1           1        2 イーハトーヴォ   名詞 普通名詞 一般 <NA>
#> 3      1           1        3             の   助詞   格助詞 <NA> <NA>
#> 4      1           1        4     すきとおっ   動詞     一般 <NA> <NA>
#> 5      1           1        5             た 助動詞     <NA> <NA> <NA>
#> 6      1           1        6             風   名詞 普通名詞 一般 <NA>
#>       cType         cForm      lForm    lemma       orth       pron   orthBase
#> 1      <NA>          <NA>       アノ     あの       あの       アノ       あの
#> 2      <NA>          <NA>       <NA>     <NA>       <NA>       <NA>       <NA>
#> 3      <NA>          <NA>         ノ       の         の         ノ         の
#> 4 五段-ラ行 連用形-促音便 スキトオル 透き通る すきとおっ スキトーッ すきとおる
#> 5 助動詞-タ   連体形-一般         タ       た         た         タ         た
#> 6      <NA>          <NA>       カゼ       風         風       カゼ         風
#>     pronBase goshu iType iForm fType fForm       kana   kanaBase       form
#> 1       アノ    和  <NA>  <NA>  <NA>  <NA>       アノ       アノ       アノ
#> 2       <NA>  <NA>  <NA>  <NA>  <NA>  <NA>       <NA>       <NA>       <NA>
#> 3         ノ    和  <NA>  <NA>  <NA>  <NA>         ノ         ノ         ノ
#> 4 スキトール    和  <NA>  <NA>  <NA>  <NA> スキトオッ スキトオル スキトオッ
#> 5         タ    和  <NA>  <NA>  <NA>  <NA>         タ         タ         タ
#> 6       カゼ    和  <NA>  <NA>  <NA>  <NA>       カゼ       カゼ       カゼ
#>     formBase iConType fConType aType               aConType aModeType
#> 1       アノ     <NA>     <NA>     0                   <NA>      <NA>
#> 2       <NA>     <NA>     <NA>  <NA>                   <NA>      <NA>
#> 3         ノ     <NA>     <NA>  <NA>                名詞%F1      <NA>
#> 4 スキトオル     <NA>     <NA>     3                     C1      <NA>
#> 5         タ     <NA>     <NA>  <NA> 動詞%F2@1,形容詞%F4@-2      <NA>
#> 6       カゼ     <NA>     <NA>     0                     C4      <NA>


## CC-CEDICT
gibasa::gbs_tokenize("它可以进行日语和汉语的语态分析", sys_dic = "/Downloads/cc-cedict") |> 
    gibasa::prettify(into = gibasa::get_dict_features("cc-cedict"))
#>   doc_id sentence_id token_id token POS1 POS2 POS3 POS4 pinyin_pron
#> 1      1           1        1    它 <NA> <NA> <NA> <NA>         ta1
#> 2      1           1        2  可以 <NA> <NA> <NA> <NA>     ke3 yi3
#> 3      1           1        3  进行 <NA> <NA> <NA> <NA>  jin4 xing2
#> 4      1           1        4  日语 <NA> <NA> <NA> <NA>     Ri4 yu3
#> 5      1           1        5    和 <NA> <NA> <NA> <NA>         he2
#> 6      1           1        6  汉语 <NA> <NA> <NA> <NA>    Han4 yu3
#> 7      1           1        7    的 <NA> <NA> <NA> <NA>         di4
#> 8      1           1        8  语态 <NA> <NA> <NA> <NA>    yu3 tai4
#> 9      1           1        9  分析 <NA> <NA> <NA> <NA>    fen1 xi1
#>   traditional_char_form simplified_char_form
#> 1                    它                   它
#> 2                  可以                 可以
#> 3                  進行                 进行
#> 4                  日語                 日语
#> 5                    龢                   和
#> 6                  漢語                 汉语
#> 7                    的                   的
#> 8                  語態                 语态
#> 9                  分析                 分析
#>                                                                              definition
#> 1                                                                                   it/
#> 2                                         can/may/possible/able to/not bad/pretty good/
#> 3 to advance/to conduct/underway/in progress/to do/to carry out/to carry on/to execute/
#> 4                                                                    Japanese language/
#> 5                                                    old variant of 和[he2]/harmonious/
#> 6                                                      Chinese language/CL:門|门[men2]/
#> 7                                                                            aim/clear/
#> 8                                                                      voice (grammar)/
#> 9                                                    to analyze/analysis/CL:個|个[ge4]/


## mecab-ko-dic
gibasa::gbs_tokenize("하네다공항한정토트백", sys_dic = "/Downloads/mecab-ko-dic") |> 
    gibasa::prettify(into = gibasa::get_dict_features("ko-dic"))
#>   doc_id sentence_id token_id  token POS meaning presence reading     type
#> 1      1           1        1 하네다 NNP    인명        F  하네다     <NA>
#> 2      1           1        2   공항 NNG    장소        T    공항     <NA>
#> 3      1           1        3   한정 NNG    <NA>        T    한정     <NA>
#> 4      1           1        4 토트백 NNG    <NA>        T  토트백 Compound
#>   first_pos last_pos             expression
#> 1      <NA>     <NA>                   <NA>
#> 2      <NA>     <NA>                   <NA>
#> 3      <NA>     <NA>                   <NA>
#> 4      <NA>     <NA> 토트/NNP/인명+백/NNG/*
```

## License

GPL (>=3).
